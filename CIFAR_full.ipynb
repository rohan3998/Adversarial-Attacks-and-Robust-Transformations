{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchattacks\n",
    "!pip install tensorboardX\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchattacks\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions import kl_divergence\n",
    "from torch.autograd import Function\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from tensorboardX import SummaryWriter\n",
    "import operator as op\n",
    "from operator import methodcaller\n",
    "from typing import Union, Tuple\n",
    "from torch.autograd import Variable\n",
    "from skimage import io\n",
    "from sklearn.cluster import KMeans\n",
    "import tensorflow as tf\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.util import img_as_float\n",
    "import cv2\n",
    "from skimage import color, data\n",
    "from skimage.restoration import denoise_tv_bregman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, in_planes, growth_rate):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, 4*growth_rate, kernel_size=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(4*growth_rate)\n",
    "        self.conv2 = nn.Conv2d(4*growth_rate, growth_rate, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(F.relu(self.bn1(x)))\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        out = torch.cat([out,x], 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Transition(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes):\n",
    "        super(Transition, self).__init__()\n",
    "        self.bn = nn.BatchNorm2d(in_planes)\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(F.relu(self.bn(x)))\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        return out\n",
    "\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, block, nblocks, growth_rate=12, reduction=0.5, num_classes=10):\n",
    "        super(DenseNet, self).__init__()\n",
    "        self.growth_rate = growth_rate\n",
    "\n",
    "        num_planes = 2*growth_rate\n",
    "        self.conv1 = nn.Conv2d(3, num_planes, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "        self.dense1 = self._make_dense_layers(block, num_planes, nblocks[0])\n",
    "        num_planes += nblocks[0]*growth_rate\n",
    "        out_planes = int(math.floor(num_planes*reduction))\n",
    "        self.trans1 = Transition(num_planes, out_planes)\n",
    "        num_planes = out_planes\n",
    "\n",
    "        self.dense2 = self._make_dense_layers(block, num_planes, nblocks[1])\n",
    "        num_planes += nblocks[1]*growth_rate\n",
    "        out_planes = int(math.floor(num_planes*reduction))\n",
    "        self.trans2 = Transition(num_planes, out_planes)\n",
    "        num_planes = out_planes\n",
    "\n",
    "        self.dense3 = self._make_dense_layers(block, num_planes, nblocks[2])\n",
    "        num_planes += nblocks[2]*growth_rate\n",
    "        out_planes = int(math.floor(num_planes*reduction))\n",
    "        self.trans3 = Transition(num_planes, out_planes)\n",
    "        num_planes = out_planes\n",
    "\n",
    "        self.dense4 = self._make_dense_layers(block, num_planes, nblocks[3])\n",
    "        num_planes += nblocks[3]*growth_rate\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(num_planes)\n",
    "        self.linear = nn.Linear(num_planes, num_classes)\n",
    "\n",
    "    def _make_dense_layers(self, block, in_planes, nblock):\n",
    "        layers = []\n",
    "        for i in range(nblock):\n",
    "            layers.append(block(in_planes, self.growth_rate))\n",
    "            in_planes += self.growth_rate\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.trans1(self.dense1(out))\n",
    "        out = self.trans2(self.dense2(out))\n",
    "        out = self.trans3(self.dense3(out))\n",
    "        out = self.dense4(out)\n",
    "        out = F.avg_pool2d(F.relu(self.bn(out)), 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def DenseNet121():\n",
    "    return DenseNet(Bottleneck, [6,12,24,16], growth_rate=32)\n",
    "\n",
    "def DenseNet169():\n",
    "    return DenseNet(Bottleneck, [6,12,32,32], growth_rate=32)\n",
    "\n",
    "def DenseNet201():\n",
    "    return DenseNet(Bottleneck, [6,12,48,32], growth_rate=32)\n",
    "\n",
    "def DenseNet161():\n",
    "    return DenseNet(Bottleneck, [6,12,36,24], growth_rate=48)\n",
    "\n",
    "def densenet_cifar():\n",
    "    return DenseNet(Bottleneck, [6,12,24,16], growth_rate=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = densenet_cifar()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model,(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=100, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "testset1 = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "test_loader1 = torch.utils.data.DataLoader(\n",
    "    testset1, batch_size=1, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "  model.train()\n",
    "  print('Training Epoch: ' + str(epoch))\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    data = data.to(device)\n",
    "    target = target.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = F.cross_entropy(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if(batch_idx % 10==0):\n",
    "      print(str(batch_idx*100) + '/' + str(60000) + ' Training Loss: ' + str(loss.item()))\n",
    "  torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "  model.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      data = data.to(device)\n",
    "      target = target.to(device)\n",
    "      output = model(data)\n",
    "      test_loss += F.cross_entropy(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  print('Testing loss: ' + str(test_loss) + ' Accuracy: '\n",
    "        + str((100. * correct / len(test_loader.dataset)).item()))"
   ]
  },
  {
   "source": [
    "Train Baseline Model:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "for iter in range(epochs):\n",
    "  train(iter)\n",
    "  print('.....................................')\n",
    "  print('Testing')\n",
    "  test()\n",
    "  print('.....................................')"
   ]
  },
  {
   "source": [
    "List of Attacks Available: Projected Gradient Descent (PGD), Fast Gradient Sign Method (FGSM), Iterative FGSM (IFGSM), Carlini Wagner L2 Attack (CWLA) and Deep Fool Attack (DF). Run on one of the attacks and then skip to next markdown."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#PGD\n",
    "\n",
    "def pgd_linf(model, X, y, epsilon, alpha, num_iter):\n",
    "    delta = torch.zeros_like(X, requires_grad=True)\n",
    "    for t in range(num_iter):\n",
    "        loss = nn.CrossEntropyLoss()(model(X + delta), y)\n",
    "        loss.backward()\n",
    "        delta.data = (delta + alpha*delta.grad.detach().sign()).clamp(-epsilon,epsilon)\n",
    "        delta.grad.zero_()\n",
    "    return delta\n",
    "\n",
    "def PGDtest(model,device,test_loader,epsilon):\n",
    "  correct=0\n",
    "  k=0\n",
    "  adv_img=[]\n",
    "  adv_img_label=[]\n",
    "  for image,label in test_loader:\n",
    "    if k==50:\n",
    "      break\n",
    "    if k%10==0:\n",
    "      print(k)\n",
    "    image,label=image.to(device),label.to(device)\n",
    "    delta=pgd_linf(model,image,label,epsilon,1e-2,10)\n",
    "    image=image+delta\n",
    "    for i in range(0,len(image)):\n",
    "      adv_img.append(image[i])\n",
    "      adv_img_label.append(label[i])\n",
    "    \n",
    "    output=model(image)\n",
    "    final_pred = output.max(1, keepdim=True)[1] \n",
    "    correct += final_pred.eq(label.data.view_as(final_pred)).sum()\n",
    "    k=k+1\n",
    "\n",
    "        \n",
    "  print(k)\n",
    "  final_acc = correct/len(adv_img)\n",
    "  print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(adv_img), final_acc))\n",
    "\n",
    "  return final_acc, adv_img,adv_img_label\n",
    "  \n",
    "acc,adv_img,adv_img_label=PGDtest(model,device,test_loader,0.3)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IFGSM\n",
    "\n",
    "def i_fgsm_attack(image,out, epsilon, data_grad,n_iter=10):\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    perturbed_image = image\n",
    "    for i in range(n_iter):\n",
    "\n",
    "        output = model(perturbed_image)\n",
    "        init_pred=output.max(1,keepdim=True)[1]\n",
    "        if init_pred.item()!=out.item():\n",
    "          continue\n",
    "\n",
    "        loss = F.nll_loss(output, out)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        data_grad = image.grad.data\n",
    "        sign_data_grad = data_grad.sign()\n",
    "\n",
    "        perturbed_image = image + epsilon*sign_data_grad\n",
    "        perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    return perturbed_image\n",
    "\n",
    "def IFGSMtest( model, device, test_loader, epsilon ):\n",
    "\n",
    "    correct = 0\n",
    "    k=0\n",
    "    adv_img = []\n",
    "    adv_img_label=[]\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        if k==1000:\n",
    "          break\n",
    "        \n",
    "        if k%100==0:\n",
    "          print(k)\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        data.requires_grad = True\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        data_grad = data.grad.data\n",
    "\n",
    "        perturbed_data = i_fgsm_attack(data, target, epsilon, data_grad,10)\n",
    "        adv_img.append(perturbed_data[0])\n",
    "        adv_img_label.append(target[0])\n",
    "        out = model(perturbed_data)\n",
    "\n",
    "        final_pred = out.max(1, keepdim=True)[1] \n",
    "        if final_pred.item()==target.item():\n",
    "          correct=correct+1\n",
    "        k=k+1\n",
    "\n",
    "        \n",
    "    print(k,len(adv_img))\n",
    "    final_acc = correct/len(adv_img)\n",
    "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(adv_img), final_acc))\n",
    "\n",
    "    return final_acc, adv_img,adv_img_label\n",
    "  \n",
    "acc,adv_img,adv_img_label=IFGSMtest(model,device,test_loader1,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FGSM\n",
    "\n",
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    perturbed_image = image + epsilon*sign_data_grad\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    return perturbed_image\n",
    "\n",
    "def FGSMtest(model, device, test_loader, epsilon):\n",
    "\n",
    "    correct = 0\n",
    "    k=0\n",
    "    adv_img = []\n",
    "    adv_img_label=[]\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        if k==1000:\n",
    "          break\n",
    "        \n",
    "        if k%100==0:\n",
    "          print(k)\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        data.requires_grad = True\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        data_grad = data.grad.data\n",
    "\n",
    "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
    "        adv_img.append(perturbed_data[0])\n",
    "        adv_img_label.append(target[0])\n",
    "\n",
    "        output = model(perturbed_data)\n",
    "\n",
    "        final_pred = output.max(1, keepdim=True)[1] \n",
    "        if final_pred.item()==target.item():\n",
    "          correct=correct+1\n",
    "        k=k+1\n",
    "\n",
    "    final_acc = correct/len(adv_img)\n",
    "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(adv_img), final_acc))\n",
    "\n",
    "    return final_acc, adv_img,adv_img_label\n",
    "  \n",
    "acc,adv_img,adv_img_label=FGSMtest(model,device,test_loader1,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DF\n",
    "\n",
    "def DeepFool(image,model):\n",
    "\n",
    "    steps = 3\n",
    "    image = image.to(device)\n",
    "\n",
    "    image.requires_grad = True\n",
    "    output = model(image)[0]\n",
    "\n",
    "    _, pre_0 = torch.max(output, 0)\n",
    "    f_0 = output[pre_0]\n",
    "    grad_f_0 = torch.autograd.grad(f_0, image,\n",
    "                                    retain_graph=False,\n",
    "                                    create_graph=False)[0]\n",
    "    num_classes = len(output)\n",
    "\n",
    "    for i in range(steps):\n",
    "        image.requires_grad = True\n",
    "        output = model(image)[0]\n",
    "        _, pre = torch.max(output, 0)\n",
    "\n",
    "        if pre != pre_0:\n",
    "            image = torch.clamp(image, min=0, max=1).detach()\n",
    "            break\n",
    "\n",
    "        r = None\n",
    "        min_value = None\n",
    "\n",
    "        for k in range(num_classes):\n",
    "            if k == pre_0:\n",
    "                continue\n",
    "\n",
    "            f_k = output[k]\n",
    "            grad_f_k = torch.autograd.grad(f_k, image,\n",
    "                                            retain_graph=True,\n",
    "                                            create_graph=True)[0]\n",
    "\n",
    "            f_prime = f_k - f_0\n",
    "            grad_f_prime = grad_f_k - grad_f_0\n",
    "            value = torch.abs(f_prime)/torch.norm(grad_f_prime)\n",
    "\n",
    "            if r is None:\n",
    "                r = (torch.abs(f_prime)/(torch.norm(grad_f_prime)**2))*grad_f_prime\n",
    "                min_value = value\n",
    "            else:\n",
    "                if min_value > value:\n",
    "                    r = (torch.abs(f_prime)/(torch.norm(grad_f_prime)**2))*grad_f_prime\n",
    "                    min_value = value\n",
    "\n",
    "        image = torch.clamp(image + r, min=0, max=1).detach()\n",
    "    return image\n",
    "\n",
    "def DFtest( model, device, test_loader):\n",
    "\n",
    "    correct = 0\n",
    "    k=0\n",
    "    adv_img = []\n",
    "    adv_img_label=[]\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        if k==1000:\n",
    "          break\n",
    "        if k%100==0:\n",
    "          print(k)\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        data.requires_grad = True\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        perturbed_data = DeepFool(data, model)\n",
    "        adv_img.append(perturbed_data[0])\n",
    "        adv_img_label.append(target[0])\n",
    "\n",
    "        output = model(perturbed_data)\n",
    "\n",
    "        final_pred = output.max(1, keepdim=True)[1] \n",
    "        if final_pred.item()==target.item():\n",
    "          correct=correct+1\n",
    "\n",
    "        k=k+1\n",
    "\n",
    "    print(k,len(adv_img),correct)\n",
    "    final_acc = correct/len(adv_img)\n",
    "    print(\"Test_Accuracy\", final_acc)\n",
    "\n",
    "    return final_acc, adv_img,adv_img_label\n",
    "\n",
    "acc, adv_img, adv_img_label = DFtest(model, device, test_loader1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CWLA\n",
    "\n",
    "def get_cuda_state(obj):\n",
    "\n",
    "    if isinstance(obj, nn.Module):\n",
    "        try:\n",
    "            return next(obj.parameters()).is_cuda\n",
    "        except StopIteration:\n",
    "            return None\n",
    "    elif hasattr(obj, 'is_cuda'):\n",
    "        return obj.is_cuda\n",
    "    else:\n",
    "        raise TypeError('unrecognized type ({}) in args'.format(type(obj)))\n",
    "\n",
    "\n",
    "def is_cuda_consistent(*args):\n",
    "\n",
    "    result = dict()\n",
    "    for v in args:\n",
    "        cur_cuda_state = get_cuda_state(v)\n",
    "        cuda_state = result.get('cuda', cur_cuda_state)\n",
    "        if cur_cuda_state is not cuda_state:\n",
    "            return False\n",
    "        result['cuda'] = cur_cuda_state\n",
    "    return True\n",
    "\n",
    "def make_cuda_consistent(refobj, *args):\n",
    "\n",
    "    ref_cuda_state = refobj if type(refobj) is bool else get_cuda_state(refobj)\n",
    "    if ref_cuda_state is None:\n",
    "        raise ValueError('cannot determine the cuda state of `refobj` ({})'\n",
    "                .format(refobj))\n",
    "    move_to_device = methodcaller('cuda' if ref_cuda_state else 'cpu')\n",
    "\n",
    "    result_args = list()\n",
    "    for v in args:\n",
    "        cuda_state = get_cuda_state(v)\n",
    "        if cuda_state != ref_cuda_state:\n",
    "            if isinstance(v, nn.Module):\n",
    "                move_to_device(v)\n",
    "            else:\n",
    "                v = move_to_device(v)\n",
    "        result_args.append(v)\n",
    "    return tuple(result_args)\n",
    "\n",
    "def predict(net, inputs):\n",
    "\n",
    "    inputs = make_cuda_consistent(net, inputs)[0]\n",
    "    inputs_var = Variable(inputs)\n",
    "    outputs_var = net(inputs_var)\n",
    "    predictions = torch.max(outputs_var.data, dim=1)[1]\n",
    "    return predictions\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "def _var2numpy(var):\n",
    "    return var.data.cpu().numpy()\n",
    "\n",
    "\n",
    "def atanh(x, eps=1e-6):\n",
    "    x = x * (1 - eps)\n",
    "    return 0.5 * torch.log((1.0 + x) / (1.0 - x))\n",
    "\n",
    "def to_tanh_space(x, box):\n",
    "    _box_mul = (box[1] - box[0]) * 0.5\n",
    "    _box_plus = (box[1] + box[0]) * 0.5\n",
    "    return atanh((x - _box_plus) / _box_mul)\n",
    "\n",
    "def from_tanh_space(x, box):\n",
    "    _box_mul = (box[1] - box[0]) * 0.5\n",
    "    _box_plus = (box[1] + box[0]) * 0.5\n",
    "    return torch.tanh(x) * _box_mul + _box_plus\n",
    "\n",
    "\n",
    "class L2Adversary(object):\n",
    "    def __init__(self, targeted=True, confidence=0.0, c_range=(1e-3, 1e10),\n",
    "                 search_steps=5, max_steps=1000, abort_early=True,\n",
    "                 box=(-1., 1.), optimizer_lr=1e-2, init_rand=False):\n",
    "        if len(c_range) != 2:\n",
    "            raise TypeError('c_range ({}) should be of form '\n",
    "                            'tuple([lower_bound, upper_bound])'\n",
    "                            .format(c_range))\n",
    "        if c_range[0] >= c_range[1]:\n",
    "            raise ValueError('c_range lower bound ({}) is expected to be less '\n",
    "                             'than c_range upper bound ({})'.format(*c_range))\n",
    "        if len(box) != 2:\n",
    "            raise TypeError('box ({}) should be of form '\n",
    "                            'tuple([lower_bound, upper_bound])'\n",
    "                            .format(box))\n",
    "        if box[0] >= box[1]:\n",
    "            raise ValueError('box lower bound ({}) is expected to be less than '\n",
    "                             'box upper bound ({})'.format(*box))\n",
    "        self.targeted = targeted\n",
    "        self.confidence = float(confidence)\n",
    "        self.c_range = (float(c_range[0]), float(c_range[1]))\n",
    "        self.binary_search_steps = search_steps\n",
    "        self.max_steps = max_steps\n",
    "        self.abort_early = abort_early\n",
    "        self.ae_tol = 1e-4  # tolerance of early abort\n",
    "        self.box = tuple(map(float, box))  # type: Tuple[float, float]\n",
    "        self.optimizer_lr = optimizer_lr\n",
    "        self.init_rand = init_rand\n",
    "        self.repeat = (self.binary_search_steps >= 10)\n",
    "\n",
    "    def __call__(self, model, inputs, targets, to_numpy=True):\n",
    "        # sanity check\n",
    "        assert isinstance(model, nn.Module)\n",
    "        assert len(inputs.size()) == 4\n",
    "        assert len(targets.size()) == 1\n",
    "\n",
    "        targets_np = targets.clone().cpu().numpy()  # type: np.ndarray\n",
    "\n",
    "        inputs = make_cuda_consistent(model, inputs)[0]  # type: torch.FloatTensor\n",
    "        targets = make_cuda_consistent(model, targets)[0]  # type: torch.FloatTensor\n",
    "\n",
    "        num_classes = model(Variable(inputs[0][None, :], requires_grad=False)).size(1)  # type: int\n",
    "        batch_size = inputs.size(0)  # type: int\n",
    "\n",
    "        lower_bounds_np = np.zeros(batch_size)\n",
    "        upper_bounds_np = np.ones(batch_size) * self.c_range[1]\n",
    "        scale_consts_np = np.ones(batch_size) * self.c_range[0]\n",
    "\n",
    "        o_best_l2 = np.ones(batch_size) * np.inf\n",
    "        o_best_l2_ppred = -np.ones(batch_size)\n",
    "        o_best_advx = inputs.clone().cpu().numpy()  # type: np.ndarray\n",
    "\n",
    "        inputs_tanh = self._to_tanh_space(inputs)  # type: torch.FloatTensor\n",
    "        inputs_tanh_var = Variable(inputs_tanh, requires_grad=False)\n",
    "\n",
    "        targets_oh = torch.zeros(targets.size() + (num_classes,))  # type: torch.FloatTensor\n",
    "        targets_oh = make_cuda_consistent(model, targets_oh)[0]\n",
    "        targets_oh.scatter_(1, targets.unsqueeze(1), 1.0)\n",
    "        targets_oh_var = Variable(targets_oh, requires_grad=False)\n",
    "\n",
    "        pert_tanh = torch.zeros(inputs.size())  # type: torch.FloatTensor\n",
    "        if self.init_rand:\n",
    "            nn.init.normal(pert_tanh, mean=0, std=1e-3)\n",
    "        pert_tanh = make_cuda_consistent(model, pert_tanh)[0]\n",
    "        pert_tanh_var = Variable(pert_tanh, requires_grad=True)\n",
    "\n",
    "        optimizer = optim.Adam([pert_tanh_var], lr=self.optimizer_lr)\n",
    "        for sstep in range(self.binary_search_steps):\n",
    "            if self.repeat and sstep == self.binary_search_steps - 1:\n",
    "                scale_consts_np = upper_bounds_np\n",
    "            scale_consts = torch.from_numpy(np.copy(scale_consts_np)).float()  # type: torch.FloatTensor\n",
    "            scale_consts = make_cuda_consistent(model, scale_consts)[0]\n",
    "            scale_consts_var = Variable(scale_consts, requires_grad=False)\n",
    "            print ('Using scale consts:', list(scale_consts_np) ) # FIXME\n",
    "\n",
    "            best_l2 = np.ones(batch_size) * np.inf\n",
    "\n",
    "            best_l2_ppred = -np.ones(batch_size)\n",
    "            prev_batch_loss = np.inf  # type: float\n",
    "            for optim_step in range(self.max_steps):\n",
    "                batch_loss, pert_norms_np, pert_outputs_np, advxs_np = \\\n",
    "                    self._optimize(model, optimizer, inputs_tanh_var,\n",
    "                                   pert_tanh_var, targets_oh_var,\n",
    "                                   scale_consts_var)\n",
    "                if optim_step % 10 == 0: print ('batch [{}] loss: {}'.format(optim_step, batch_loss))  # FIXME\n",
    "\n",
    "                if self.abort_early and not optim_step % (self.max_steps // 10):\n",
    "                    if batch_loss > prev_batch_loss * (1 - self.ae_tol):\n",
    "                        break\n",
    "                    prev_batch_loss = batch_loss\n",
    "                pert_predictions_np = np.argmax(pert_outputs_np, axis=1)\n",
    "                comp_pert_predictions_np = np.argmax(\n",
    "                        self._compensate_confidence(pert_outputs_np,\n",
    "                                                    targets_np),\n",
    "                        axis=1)\n",
    "                for i in range(batch_size):\n",
    "                    l2 = pert_norms_np[i]\n",
    "                    cppred = comp_pert_predictions_np[i]\n",
    "                    ppred = pert_predictions_np[i]\n",
    "                    tlabel = targets_np[i]\n",
    "                    ax = advxs_np[i]\n",
    "                    if self._attack_successful(cppred, tlabel):\n",
    "                        assert cppred == ppred\n",
    "                        if l2 < best_l2[i]:\n",
    "                            best_l2[i] = l2\n",
    "                            best_l2_ppred[i] = ppred\n",
    "                        if l2 < o_best_l2[i]:\n",
    "                            o_best_l2[i] = l2\n",
    "                            o_best_l2_ppred[i] = ppred\n",
    "                            o_best_advx[i] = ax\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                tlabel = targets_np[i]\n",
    "                assert best_l2_ppred[i] == -1 or \\\n",
    "                       self._attack_successful(best_l2_ppred[i], tlabel)\n",
    "                assert o_best_l2_ppred[i] == -1 or \\\n",
    "                       self._attack_successful(o_best_l2_ppred[i], tlabel)\n",
    "                if best_l2_ppred[i] != -1:\n",
    "                    if scale_consts_np[i] < upper_bounds_np[i]:\n",
    "                        upper_bounds_np[i] = scale_consts_np[i]\n",
    "\n",
    "                    if upper_bounds_np[i] < self.c_range[1] * 0.1:\n",
    "                        scale_consts_np[i] = (lower_bounds_np[i] + upper_bounds_np[i]) / 2\n",
    "                else:\n",
    "                    if scale_consts_np[i] > lower_bounds_np[i]:\n",
    "                        lower_bounds_np[i] = scale_consts_np[i]\n",
    "                    if upper_bounds_np[i] < self.c_range[1] * 0.1:\n",
    "                        scale_consts_np[i] = (lower_bounds_np[i] + upper_bounds_np[i]) / 2\n",
    "                    else:\n",
    "                        scale_consts_np[i] *= 10\n",
    "\n",
    "        if not to_numpy:\n",
    "            o_best_advx = torch.from_numpy(o_best_advx).float()\n",
    "        return o_best_advx\n",
    "\n",
    "    def _optimize(self, model, optimizer, inputs_tanh_var, pert_tanh_var,\n",
    "                  targets_oh_var, c_var):\n",
    "\n",
    "        advxs_var = self._from_tanh_space(inputs_tanh_var + pert_tanh_var)  # type: Variable\n",
    "        # the perturbed activation before softmax\n",
    "        pert_outputs_var = model(advxs_var)  # type: Variable\n",
    "        # the original inputs\n",
    "        inputs_var = self._from_tanh_space(inputs_tanh_var)  # type: Variable\n",
    "\n",
    "        perts_norm_var = torch.pow(advxs_var - inputs_var, 2)\n",
    "        perts_norm_var = torch.sum(perts_norm_var.view(\n",
    "                perts_norm_var.size(0), -1), 1)\n",
    "\n",
    "        target_activ_var = torch.sum(targets_oh_var * pert_outputs_var, 1)\n",
    "        inf = 1e4  \n",
    "        assert (pert_outputs_var.max(1)[0] >= -inf).all(), 'assumption failed'\n",
    "\n",
    "        maxother_activ_var = torch.max(((1 - targets_oh_var) * pert_outputs_var\n",
    "                                        - targets_oh_var * inf), 1)[0]\n",
    "\n",
    "        if self.targeted:\n",
    "            f_var = torch.clamp(maxother_activ_var - target_activ_var\n",
    "                                + self.confidence, min=0.0)\n",
    "        else:\n",
    "            f_var = torch.clamp(target_activ_var - maxother_activ_var\n",
    "                                + self.confidence, min=0.0)\n",
    "        batch_loss_var = torch.sum(perts_norm_var + c_var * f_var)  # type: Variable\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss_var.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_loss = batch_loss_var.item()  # type: float\n",
    "        pert_norms_np = _var2numpy(perts_norm_var)\n",
    "        pert_outputs_np = _var2numpy(pert_outputs_var)\n",
    "        advxs_np = _var2numpy(advxs_var)\n",
    "        return batch_loss, pert_norms_np, pert_outputs_np, advxs_np\n",
    "\n",
    "    def _attack_successful(self, prediction, target):\n",
    "\n",
    "        if self.targeted:\n",
    "            return prediction == target\n",
    "        else:\n",
    "            return prediction != target\n",
    "\n",
    "    # noinspection PyUnresolvedReferences\n",
    "    def _compensate_confidence(self, outputs, targets):\n",
    "\n",
    "        outputs_comp = np.copy(outputs)\n",
    "        rng = np.arange(targets.shape[0])\n",
    "        if self.targeted:\n",
    "            outputs_comp[rng, targets] -= self.confidence\n",
    "        else:\n",
    "            outputs_comp[rng, targets] += self.confidence\n",
    "        return outputs_comp\n",
    "\n",
    "    def _to_tanh_space(self, x):\n",
    "        return to_tanh_space(x, self.box)\n",
    "\n",
    "    def _from_tanh_space(self, x):\n",
    "        return from_tanh_space(x, self.box)\n",
    "\n",
    "mean=(0.4914, 0.4822, 0.4465)\n",
    "std=(0.2023, 0.1994, 0.2010)\n",
    "inputs_box=(min((0 - m) / s for m, s in zip(mean, std)),max((1 - m) / s for m, s in zip(mean, std)))\n",
    "adversary = L2Adversary(targeted=False,\n",
    "                           confidence=0.0,\n",
    "                           search_steps=10,\n",
    "                           box=inputs_box,\n",
    "                           optimizer_lr=5e-4)\n",
    "\n",
    "model.eval()\n",
    "correct=0\n",
    "total=0\n",
    "loss=0\n",
    "adv_img=[]\n",
    "adv_img_label=[]\n",
    "for images,labels in test_loader:\n",
    "  adv_images=adversary(model, images, labels, to_numpy=False).cuda()\n",
    "  for i in range(0,len(images)):\n",
    "    adv_img.append(adv_images[i])\n",
    "    adv_img_label.append(labels[i])\n",
    "  output=model(adv_images)\n",
    "  labels=labels.to(device)\n",
    "  loss+=F.cross_entropy(output,labels).item()\n",
    "  pred=output.data.max(1,keepdim=True)[1]\n",
    "  correct+=pred.eq(labels.data.view_as(pred)).sum()\n",
    "\n",
    "loss/=len(test_loader.dataset)\n",
    "print('Loss: '+str(loss)+' Accuracy:'+str((100. * correct / len(test_loader.dataset)).item()))"
   ]
  },
  {
   "source": [
    "That was our list of attacks. Now some in between preprocessing first."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "adv_img=torch.stack(adv_img)\n",
    "adv_img_label=torch.stack(adv_img_label)\n",
    "adv_dataset=torch.utils.data.TensorDataset(adv_img,adv_img_label)\n",
    "adv_loader=torch.utils.data.DataLoader(adv_dataset,batch_size=100)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "Now for our list of defenses: JPEG Compression (this is our best one), K-Means, Gaussian Smoothing, Total Variance Maximization (TVM) and Vector-Quantized Variational Auto Encoder (VQVAE). Run any one of these methods. It will show the final accuracy as well as a plot of 12 images which consists of 4 original images then 4 images of them after being attacked and then the final 4 are the reconstructed version of them after passing through the defense."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KMeans\n",
    "\n",
    "def k_means(data,n_clusters=50):\n",
    "  kmeans = KMeans(n_clusters)\n",
    "  rows=data.shape[2]\n",
    "  cols=data.shape[3]\n",
    "  recon=[]\n",
    "  for image in data:\n",
    "    \n",
    "    image2 = image.reshape(rows*cols, 3)\n",
    "    kmeans.fit(image2.detach().cpu())\n",
    "    compressed_image = kmeans.cluster_centers_[kmeans.labels_]\n",
    "    compressed_image = np.clip(compressed_image.astype('float'), -1, 1)\n",
    "    compressed_image = compressed_image.reshape(3,rows, cols)\n",
    "    recon.append(torch.from_numpy(compressed_image))\n",
    "\n",
    "  recon=torch.stack(recon)\n",
    "  return recon.float()\n",
    "\n",
    "recons_img=[]\n",
    "recons_img_label=[]\n",
    "loss=0\n",
    "correct=0\n",
    "j=0\n",
    "for images,label in adv_loader:\n",
    "  if(j==10):\n",
    "    break\n",
    "  print(j)\n",
    "  images = images.to('cuda')\n",
    "  x_tilde= k_means(images)\n",
    "  for i in range(0,len(images)):\n",
    "    recons_img.append(x_tilde[i])\n",
    "    recons_img_label.append(label[i])\n",
    "  output=model(x_tilde.cuda())\n",
    "  label=label.to(device)\n",
    "  loss+=F.cross_entropy(output,label).item()\n",
    "  pred=output.data.max(1,keepdim=True)[1]\n",
    "  correct+=pred.eq(label.data.view_as(pred)).sum()\n",
    "  j=j+1\n",
    "\n",
    "loss/=len(recons_img)\n",
    "print('Loss: '+str(loss)+' Accuracy:'+str((100. * correct / len(recons_img)).item()))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "test_iter = test_loader.__iter__()\n",
    "adv_iter=adv_loader.__iter__()\n",
    "test_imgs,_=next(test_iter)\n",
    "adv_imgs,_=next(adv_iter)\n",
    "adv_imgs=adv_imgs.cpu().detach().numpy()\n",
    "test_imgs=test_imgs.cpu().detach().numpy()\n",
    "plt.subplot(4,3,1)\n",
    "plt.imshow(np.transpose(test_imgs[0],(1,2,0)))\n",
    "plt.subplot(4,3,2)\n",
    "plt.imshow(np.transpose(adv_imgs[0],(1,2,0)))\n",
    "plt.subplot(4,3,3)\n",
    "plt.imshow(np.transpose(recons_img[0].cpu().detach().numpy(),(1,2,0)))\n",
    "plt.subplot(4,3,4)\n",
    "plt.imshow(np.transpose(test_imgs[1],(1,2,0)))\n",
    "plt.subplot(4,3,5)\n",
    "plt.imshow(np.transpose(adv_imgs[1],(1,2,0)))\n",
    "plt.subplot(4,3,6)\n",
    "plt.imshow(np.transpose(recons_img[1].cpu().detach().numpy(),(1,2,0)))\n",
    "plt.subplot(4,3,7)\n",
    "plt.imshow(np.transpose(test_imgs[2],(1,2,0)))\n",
    "plt.subplot(4,3,8)\n",
    "plt.imshow(np.transpose(adv_imgs[2],(1,2,0)))\n",
    "plt.subplot(4,3,9)\n",
    "plt.imshow(np.transpose(recons_img[2].cpu().detach().numpy(),(1,2,0)))\n",
    "plt.subplot(4,3,10)\n",
    "plt.imshow(np.transpose(test_imgs[3],(1,2,0)))\n",
    "plt.subplot(4,3,11)\n",
    "plt.imshow(np.transpose(adv_imgs[3],(1,2,0)))\n",
    "plt.subplot(4,3,12)\n",
    "plt.imshow(np.transpose(recons_img[3].cpu().detach().numpy(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VQVAE\n",
    "\n",
    "class VectorQuant(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx,input,codebook):\n",
    "        with torch.no_grad():\n",
    "            embedding_size=codebook.size(1)\n",
    "            input_size=input.size()\n",
    "            input_flatten=input.view(-1,embedding_size)\n",
    "\n",
    "            codebook_mse=torch.sum(codebook**2,dim=1)\n",
    "            input_mse=torch.sum(input_flatten**2,dim=1,keepdim=True)\n",
    "\n",
    "            d=torch.addmm(codebook_mse+input_mse,input_flatten,codebook.t(),alpha=-2.0,beta=1.0)\n",
    "\n",
    "            _,indice=torch.min(d,dim=1)\n",
    "            indice=indice.view(*input_size[:-1])\n",
    "            ctx.mark_non_differentiable(indice)\n",
    "\n",
    "            return indice\n",
    "\n",
    "class VectorQuantST(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx,input,codebook):\n",
    "        indice=vq(input,codebook)\n",
    "        indice=indice.view(-1)\n",
    "        ctx.save_for_backward(indice,codebook)\n",
    "        ctx.mark_non_differentiable(indice)\n",
    "\n",
    "        codes=torch.index_select(codebook,dim=0,index=indice)\n",
    "        codes=codes.view_as(input)\n",
    "\n",
    "        return (codes,indice)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx,grad_out,grad_idx):\n",
    "        grad_in,grad_cb=None,None\n",
    "\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_in=grad_out.clone()\n",
    "        \n",
    "        if ctx.needs_input_grad[1]:\n",
    "            indice,codebook=ctx.saved_tensors\n",
    "            embedding_size=codebook.size(1)\n",
    "\n",
    "            grad_out=(grad_out.contiguous().view(-1,embedding_size))\n",
    "            grad_cb=torch.zeros_like(codebook)\n",
    "            grad_cb.index_add_(0,indice,grad_out)\n",
    "        \n",
    "        return (grad_in,grad_cb)\n",
    "\n",
    "vq=VectorQuant.apply\n",
    "vq_st=VectorQuantST.apply\n",
    "\n",
    "def to_scalar(arr):\n",
    "    if type(arr)==list:\n",
    "        return [x.item() for x in arr]\n",
    "    else:\n",
    "        return arr.item()\n",
    "\n",
    "def weights_init(m):\n",
    "    classname=m.__class__.__name__\n",
    "    if classname.find('Conv')!=-1:\n",
    "        try:\n",
    "            nn.init.xavier_uniform_(m.weight.data)\n",
    "            m.bias.data.fill_(0)\n",
    "        except AttributeError:\n",
    "            print(\"Skipping initialization of \", classname)\n",
    "\n",
    "class VQEmbedding(nn.Module):\n",
    "    def __init__(self, K, D):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(K, D)\n",
    "        self.embedding.weight.data.uniform_(-1./K, 1./K)\n",
    "\n",
    "    def forward(self, z_e_x):\n",
    "        z_e_x_ = z_e_x.permute(0, 2, 3, 1).contiguous()\n",
    "        latents = vq(z_e_x_, self.embedding.weight)\n",
    "        return latents\n",
    "\n",
    "    def straight_through(self, z_e_x):\n",
    "        z_e_x_ = z_e_x.permute(0, 2, 3, 1).contiguous()\n",
    "        z_q_x_, indices = vq_st(z_e_x_, self.embedding.weight.detach())\n",
    "        z_q_x = z_q_x_.permute(0, 3, 1, 2).contiguous()\n",
    "\n",
    "        z_q_x_bar_flatten = torch.index_select(self.embedding.weight,\n",
    "            dim=0, index=indices)\n",
    "        z_q_x_bar_ = z_q_x_bar_flatten.view_as(z_e_x_)\n",
    "        z_q_x_bar = z_q_x_bar_.permute(0, 3, 1, 2).contiguous()\n",
    "\n",
    "        return z_q_x, z_q_x_bar\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(dim, dim, 3, 1, 1),\n",
    "            nn.BatchNorm2d(dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(dim, dim, 1),\n",
    "            nn.BatchNorm2d(dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class VectorQuantizedVAE(nn.Module):\n",
    "    def __init__(self, input_dim, dim, K=512):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(input_dim, dim, 4, 2, 1),\n",
    "            nn.BatchNorm2d(dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(dim, dim, 4, 2, 1),\n",
    "            ResBlock(dim),\n",
    "            ResBlock(dim),\n",
    "        )\n",
    "\n",
    "        self.codebook = VQEmbedding(K, dim)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            ResBlock(dim),\n",
    "            ResBlock(dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(dim, dim, 4, 2, 1),\n",
    "            nn.BatchNorm2d(dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(dim, input_dim, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.apply(weights_init)\n",
    "\n",
    "    def encode(self, x):\n",
    "        z_e_x = self.encoder(x)\n",
    "        latents = self.codebook(z_e_x)\n",
    "        return latents\n",
    "\n",
    "    def decode(self, latents):\n",
    "        z_q_x = self.codebook.embedding(latents).permute(0, 3, 1, 2)  # (B, D, H, W)\n",
    "        x_tilde = self.decoder(z_q_x)\n",
    "        return x_tilde\n",
    "\n",
    "    def forward(self, x):\n",
    "        z_e_x = self.encoder(x)\n",
    "        z_q_x_st, z_q_x = self.codebook.straight_through(z_e_x)\n",
    "        x_tilde = self.decoder(z_q_x_st)\n",
    "        return x_tilde, z_e_x, z_q_x\n",
    "\n",
    "testmodel = VectorQuantizedVAE(3, 256, 512).to('cuda')\n",
    "testmodel.load_state_dict(torch.load('/content/best_cifar.pt'))\n",
    "testmodel.eval()\n",
    "\n",
    "recons_img=[]\n",
    "recons_img_label=[]\n",
    "loss=0\n",
    "correct=0\n",
    "j=0\n",
    "for images,label in adv_loader:\n",
    "  if(j==10):\n",
    "    break\n",
    "\n",
    "  print(j)\n",
    "  images = images.to('cuda')\n",
    "  x_tilde,_,_ = testmodel(images)\n",
    "  for i in range(0,len(images)):\n",
    "    recons_img.append(x_tilde[i])\n",
    "    recons_img_label.append(label[i])\n",
    "  output=model(x_tilde)\n",
    "  label=label.to(device)\n",
    "  loss+=F.cross_entropy(output,label).item()\n",
    "  pred=output.data.max(1,keepdim=True)[1]\n",
    "  correct+=pred.eq(label.data.view_as(pred)).sum()\n",
    "  j=j+1\n",
    "\n",
    "loss/=len(recons_img)\n",
    "print('Loss: '+str(loss)+' Accuracy:'+str((100. * correct / len(recons_img)).item()))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "test_iter = test_loader.__iter__()\n",
    "adv_iter=adv_loader.__iter__()\n",
    "test_imgs,_=next(test_iter)\n",
    "adv_imgs,_=next(adv_iter)\n",
    "adv_imgs=adv_imgs.cpu().detach().numpy()\n",
    "test_imgs=test_imgs.cpu().detach().numpy()\n",
    "plt.subplot(4,3,1)\n",
    "plt.imshow(np.transpose(test_imgs[0],(1,2,0)))\n",
    "plt.subplot(4,3,2)\n",
    "plt.imshow(np.transpose(adv_imgs[0],(1,2,0)))\n",
    "plt.subplot(4,3,3)\n",
    "plt.imshow(np.transpose(recons_img[0].cpu().detach().numpy(),(1,2,0)))\n",
    "plt.subplot(4,3,4)\n",
    "plt.imshow(np.transpose(test_imgs[1],(1,2,0)))\n",
    "plt.subplot(4,3,5)\n",
    "plt.imshow(np.transpose(adv_imgs[1],(1,2,0)))\n",
    "plt.subplot(4,3,6)\n",
    "plt.imshow(np.transpose(recons_img[1].cpu().detach().numpy(),(1,2,0)))\n",
    "plt.subplot(4,3,7)\n",
    "plt.imshow(np.transpose(test_imgs[2],(1,2,0)))\n",
    "plt.subplot(4,3,8)\n",
    "plt.imshow(np.transpose(adv_imgs[2],(1,2,0)))\n",
    "plt.subplot(4,3,9)\n",
    "plt.imshow(np.transpose(recons_img[2].cpu().detach().numpy(),(1,2,0)))\n",
    "plt.subplot(4,3,10)\n",
    "plt.imshow(np.transpose(test_imgs[3],(1,2,0)))\n",
    "plt.subplot(4,3,11)\n",
    "plt.imshow(np.transpose(adv_imgs[3],(1,2,0)))\n",
    "plt.subplot(4,3,12)\n",
    "plt.imshow(np.transpose(recons_img[3].cpu().detach().numpy(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JPEG\n",
    "\n",
    "def jpeg(x, quality=10):\n",
    "    myimg=x[0].detach().cpu().numpy()\n",
    "    myimg=np.transpose(myimg,(1,2,0))\n",
    "    myimg=np.clip(myimg, -1, 1)\n",
    "    myimg=img_as_ubyte(myimg)\n",
    "    myimg=tf.image.decode_jpeg(tf.image.encode_jpeg(myimg, format='rgb', quality=quality),channels=3)\n",
    "    myimg=img_as_float(myimg)\n",
    "    myimg=np.transpose(myimg,(2,0,1))\n",
    "    y=torch.FloatTensor(myimg)\n",
    "    return y\n",
    "\n",
    "adv_dataset=torch.utils.data.TensorDataset(adv_img,adv_img_label)\n",
    "adv_loader=torch.utils.data.DataLoader(adv_dataset,batch_size=1)\n",
    "\n",
    "recons_img=[]\n",
    "recons_img_label=[]\n",
    "loss=0\n",
    "correct=0\n",
    "j=0\n",
    "for images,label in adv_loader:\n",
    "  if(j==1000):\n",
    "    break\n",
    "  if j%100==0:\n",
    "    print(j)\n",
    "  images = images.to('cuda')\n",
    "  x_tilde= jpeg(images)\n",
    "  recons_img.append(x_tilde)\n",
    "  recons_img_label.append(label)\n",
    "\n",
    "  x_tilde = x_tilde.reshape(1,3,32,32)\n",
    "  x_tilde = x_tilde.type(torch.cuda.FloatTensor)\n",
    "  x_tilde = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))(x_tilde)\n",
    "  output=model(x_tilde.cuda())\n",
    "  label=label.to(device)\n",
    "  loss+=F.cross_entropy(output,label).item()\n",
    "  pred=output.data.max(1,keepdim=True)[1]\n",
    "  correct+=pred.eq(label.data.view_as(pred)).sum()\n",
    "  j=j+1\n",
    "\n",
    "loss/=len(recons_img)\n",
    "print('Loss: '+str(loss)+' Accuracy:'+str((100. * correct / len(recons_img)).item()))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "test_iter = test_loader.__iter__()\n",
    "adv_iter=adv_loader.__iter__()\n",
    "test_imgs,_=next(test_iter)\n",
    "adv_imgs,_=next(adv_iter)\n",
    "adv_imgs=adv_imgs.cpu().detach().numpy()\n",
    "test_imgs=test_imgs.cpu().detach().numpy()\n",
    "\n",
    "plt.subplot(4,3,1)\n",
    "plt.imshow(np.transpose(test_imgs[0],(1,2,0)))\n",
    "plt.subplot(4,3,2)\n",
    "plt.imshow(np.transpose(adv_imgs[0],(1,2,0)))\n",
    "plt.subplot(4,3,3)\n",
    "plt.imshow(np.transpose(img_as_ubyte(recons_img[0].cpu().detach().numpy()),(1,2,0)))\n",
    "plt.subplot(4,3,4)\n",
    "plt.imshow(np.transpose(test_imgs[1],(1,2,0)))\n",
    "plt.subplot(4,3,5)\n",
    "adv_imgs,_=next(adv_iter)\n",
    "adv_imgs=adv_imgs.cpu().detach().numpy()\n",
    "plt.imshow(np.transpose(adv_imgs[0],(1,2,0)))\n",
    "plt.subplot(4,3,6)\n",
    "plt.imshow(np.transpose(img_as_ubyte(recons_img[1].cpu().detach().numpy()),(1,2,0)))\n",
    "plt.subplot(4,3,7)\n",
    "plt.imshow(np.transpose(test_imgs[2],(1,2,0)))\n",
    "plt.subplot(4,3,8)\n",
    "adv_imgs,_=next(adv_iter)\n",
    "adv_imgs=adv_imgs.cpu().detach().numpy()\n",
    "plt.imshow(np.transpose(adv_imgs[0],(1,2,0)))\n",
    "plt.subplot(4,3,9)\n",
    "plt.imshow(np.transpose(img_as_ubyte(recons_img[2].cpu().detach().numpy()),(1,2,0)))\n",
    "plt.subplot(4,3,10)\n",
    "plt.imshow(np.transpose(test_imgs[3],(1,2,0)))\n",
    "plt.subplot(4,3,11)\n",
    "adv_imgs,_=next(adv_iter)\n",
    "adv_imgs=adv_imgs.cpu().detach().numpy()\n",
    "plt.imshow(np.transpose(adv_imgs[0],(1,2,0)))\n",
    "plt.subplot(4,3,12)\n",
    "plt.imshow(np.transpose(img_as_ubyte(recons_img[3].cpu().detach().numpy()),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Smoothing\n",
    "\n",
    "def gaussian(data):\n",
    "  rows=data.shape[2]\n",
    "  cols=data.shape[3]\n",
    "  recon=[]\n",
    "  for image in data:\n",
    "    image = image.reshape(rows,cols,3)\n",
    "    image2 = image.cpu()\n",
    "    image2=image2.detach().numpy()\n",
    "    blur = cv2.GaussianBlur(np.float32(image2),(5,5),sigmaX=0,sigmaY=0.3)\n",
    "    compressed_image = blur.reshape(3,rows, cols)\n",
    "    compressed_image = torch.from_numpy(compressed_image)\n",
    "    compressed_image = compressed_image.to('cuda')\n",
    "    recon.append(compressed_image)\n",
    "\n",
    "  recon=torch.stack(recon)\n",
    "  return recon\n",
    "\n",
    "recons_img=[]\n",
    "recons_img_label=[]\n",
    "loss=0\n",
    "correct=0\n",
    "j=0\n",
    "for images,label in adv_loader:\n",
    "  if(j==10):\n",
    "    break\n",
    "  print(j)\n",
    "  images = images.to('cuda')\n",
    "  x_tilde= gaussian(images)\n",
    "  for i in range(0,len(images)):\n",
    "    recons_img.append(x_tilde[i])\n",
    "    recons_img_label.append(label[i])\n",
    "  output=model(x_tilde.cuda())\n",
    "  label=label.to(device)\n",
    "  loss+=F.cross_entropy(output,label).item()\n",
    "  pred=output.data.max(1,keepdim=True)[1]\n",
    "  correct+=pred.eq(label.data.view_as(pred)).sum()\n",
    "  j=j+1\n",
    "\n",
    "loss/=len(recons_img)\n",
    "print('Loss: '+str(loss)+' Accuracy:'+str((100. * correct / len(recons_img)).item()))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "test_iter = test_loader.__iter__()\n",
    "adv_iter=adv_loader.__iter__()\n",
    "test_imgs,_=next(test_iter)\n",
    "adv_imgs,_=next(adv_iter)\n",
    "adv_imgs=adv_imgs.cpu().detach().numpy()\n",
    "test_imgs=test_imgs.cpu().detach().numpy()\n",
    "plt.subplot(4,3,1)\n",
    "plt.imshow(np.transpose(test_imgs[0],(1,2,0)))\n",
    "plt.subplot(4,3,2)\n",
    "plt.imshow(np.transpose(adv_imgs[0],(1,2,0)))\n",
    "plt.subplot(4,3,3)\n",
    "plt.imshow(np.transpose(recons_img[0].cpu().detach().numpy(),(1,2,0)))\n",
    "plt.subplot(4,3,4)\n",
    "plt.imshow(np.transpose(test_imgs[1],(1,2,0)))\n",
    "plt.subplot(4,3,5)\n",
    "plt.imshow(np.transpose(adv_imgs[1],(1,2,0)))\n",
    "plt.subplot(4,3,6)\n",
    "plt.imshow(np.transpose(recons_img[1].cpu().detach().numpy(),(1,2,0)))\n",
    "plt.subplot(4,3,7)\n",
    "plt.imshow(np.transpose(test_imgs[2],(1,2,0)))\n",
    "plt.subplot(4,3,8)\n",
    "plt.imshow(np.transpose(adv_imgs[2],(1,2,0)))\n",
    "plt.subplot(4,3,9)\n",
    "plt.imshow(np.transpose(recons_img[2].cpu().detach().numpy(),(1,2,0)))\n",
    "plt.subplot(4,3,10)\n",
    "plt.imshow(np.transpose(test_imgs[3],(1,2,0)))\n",
    "plt.subplot(4,3,11)\n",
    "plt.imshow(np.transpose(adv_imgs[3],(1,2,0)))\n",
    "plt.subplot(4,3,12)\n",
    "plt.imshow(np.transpose(recons_img[3].cpu().detach().numpy(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TVM\n",
    "\n",
    "def tvm(data,drop_rate=0.5,weights=0.03):\n",
    "  rows=data.shape[2]\n",
    "  cols=data.shape[3]\n",
    "  recon=[]\n",
    "  for image in data:\n",
    "    image2 = image.reshape(rows,cols,3)\n",
    "    image2 = image2.cpu()\n",
    "    image2=image2.detach().numpy()\n",
    "    new_image = denoise_tv_bregman(image2,weight=5)\n",
    "    compressed_image = new_image.reshape(3,rows, cols)\n",
    "    compressed_image = torch.from_numpy(compressed_image)\n",
    "    compressed_image = compressed_image.to('cuda')\n",
    "    recon.append(compressed_image)\n",
    "\n",
    "  recon=torch.stack(recon)\n",
    "  return recon\n",
    "adv_dataset=torch.utils.data.TensorDataset(adv_img,adv_img_label)\n",
    "adv_loader=torch.utils.data.DataLoader(adv_dataset,batch_size=100)\n",
    "\n",
    "recons_img=[]\n",
    "recons_img_label=[]\n",
    "loss=0\n",
    "correct=0\n",
    "j=0\n",
    "for images,label in adv_loader:\n",
    "  if(j==10):\n",
    "    break\n",
    "  print(j)\n",
    "  images = images.to('cuda')\n",
    "  x_tilde= tvm(images)\n",
    "  for i in range(0,len(images)):\n",
    "    recons_img.append(x_tilde[i])\n",
    "    recons_img_label.append(label[i])\n",
    "  output=model(x_tilde.cuda())\n",
    "  label=label.to(device)\n",
    "  loss+=F.cross_entropy(output,label).item()\n",
    "  pred=output.data.max(1,keepdim=True)[1]\n",
    "  correct+=pred.eq(label.data.view_as(pred)).sum()\n",
    "  j=j+1\n",
    "\n",
    "loss/=len(recons_img)\n",
    "print('Loss: '+str(loss)+' Accuracy:'+str((100. * correct / len(recons_img)).item()))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "test_iter = test_loader.__iter__()\n",
    "adv_iter=adv_loader.__iter__()\n",
    "test_imgs,_=next(test_iter)\n",
    "adv_imgs,_=next(adv_iter)\n",
    "adv_imgs=adv_imgs.cpu().detach().numpy()\n",
    "test_imgs=test_imgs.cpu().detach().numpy()\n",
    "plt.subplot(4,3,1)\n",
    "plt.imshow(np.transpose(test_imgs[0],(1,2,0)))\n",
    "plt.subplot(4,3,2)\n",
    "plt.imshow(np.transpose(adv_imgs[0],(1,2,0)))\n",
    "plt.subplot(4,3,3)\n",
    "plt.imshow(np.transpose(recons_img[0].cpu().detach().numpy(),(1,2,0)))\n",
    "plt.subplot(4,3,4)\n",
    "plt.imshow(np.transpose(test_imgs[1],(1,2,0)))\n",
    "plt.subplot(4,3,5)\n",
    "plt.imshow(np.transpose(adv_imgs[1],(1,2,0)))\n",
    "plt.subplot(4,3,6)\n",
    "plt.imshow(np.transpose(recons_img[1].cpu().detach().numpy(),(1,2,0)))\n",
    "plt.subplot(4,3,7)\n",
    "plt.imshow(np.transpose(test_imgs[2],(1,2,0)))\n",
    "plt.subplot(4,3,8)\n",
    "plt.imshow(np.transpose(adv_imgs[2],(1,2,0)))\n",
    "plt.subplot(4,3,9)\n",
    "plt.imshow(np.transpose(recons_img[2].cpu().detach().numpy(),(1,2,0)))\n",
    "plt.subplot(4,3,10)\n",
    "plt.imshow(np.transpose(test_imgs[3],(1,2,0)))\n",
    "plt.subplot(4,3,11)\n",
    "plt.imshow(np.transpose(adv_imgs[3],(1,2,0)))\n",
    "plt.subplot(4,3,12)\n",
    "plt.imshow(np.transpose(recons_img[3].cpu().detach().numpy(),(1,2,0)))"
   ]
  }
 ]
}